import tensorflow as tf
from tensorflow import keras
#!pip install name
"""
we import the necessary modules from TensorFlow and Keras.
The line #!pip install name is a comment indicating that the
code is suggesting installing a package named "name" but 
it is not actually executing the installation.
"""

train_data_dir = 'MY_data/train'
test_data_dir = 'MY_data/test'

"""
These lines define the paths to the training
and test data directories. Adjust the paths
according to the location of your data.
"""

train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

"""
These lines create instances of ImageDataGenerator 
for both training and testing. The rescale argument 
is used to scale the pixel values of the images between 0 and 1.
"""

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size = (150,150),
    batch_size = 32,
    class_mode = 'categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_data_dir,
    target_size = (150,150),
    batch_size = 32,
    class_mode = 'categorical'
)

"""
These lines set up the data generators for training and testing.
The flow_from_directory method generates batches of image data
from the specified directory. It automatically infers the class
labels based on the subdirectories in the directory.
"""

model = keras.Sequential([
    keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)),
    keras.layers.MaxPooling2D((2,2)),
    keras.layers.Conv2D(64,(3,3),activation = 'relu'),
    keras.layers.MaxPooling2D((2,2)),
    keras.layers.Conv2D(128,(3,3),activation='relu'),
    keras.layers.MaxPooling2D((2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(128,activation = 'relu'),
    keras.layers.Dense(10,activation = 'softmax')
])


"""
This block defines the architecture of the model using the Keras Sequential API. 
It consists of convolutional and pooling layers followed by a flatten layer and 
two dense layers. The model's input shape is (150, 150, 3) for RGB images, and 
the final dense layer has 10 units with a softmax activation for multiclass classification.
"""

model.compile(optimizer = 'adam',
             loss = 'categorical_crossentropy',
             metrics = ['accuracy'])

"""
This line compiles the model, specifying the optimizer,
loss function, and metrics to be used during training.
"""

model.fit(
    train_generator,
    epochs = 10,
    validation_data = test_generator
)

"""
This code block trains the model using the fit method.
It performs training for 10 epochs using the data generated by 
train_generator and validates the model using the data from test_generator.
"""

model.save('saved_model.h5')
"""
This line saves the trained model to a file named 
"saved_model.h5" in the current directory.
"""

import numpy as np
from tensorflow.keras.preprocessing import image

# Load the saved model
loaded_model = tf.keras.models.load_model('saved_model.h5')

# Define the class names
class_names = ['Apple', 'avocado', 'Banana','cherry','kiwi','mango','orange','pinenapple','strawberries','watermelon']  # Replace with your actual class names

# Define the image paths
image_paths = ['image1.jpg', 'image2.jpg']

# Iterate over the image paths and make predictions
for path in image_paths:
    # Load and preprocess the image
    img = image.load_img(path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    # Make the prediction
    prediction = loaded_model.predict(img_array)
    predicted_class_index = np.argmax(prediction)
    predicted_class = class_names[predicted_class_index]
    probability = prediction[0][predicted_class_index]

    print(f"Image: {path}")
    print(f"Predicted class: {predicted_class}")
    print(f"Probability: {probability}")
    print(f"Prediction probabilities for all classes: {prediction[0]}\n")
